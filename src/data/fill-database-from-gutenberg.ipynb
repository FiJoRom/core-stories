{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading LabMT with stopVal=0.0, for 10222 words\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "sys.path.append(\"/Users/andyreagan/tools/python\")\n",
    "from kitchentable.dogtoys import *\n",
    "from json import loads\n",
    "from re import findall,UNICODE\n",
    "from labMTsimple.labMTsimple.speedy import LabMT\n",
    "my_LabMT = LabMT()\n",
    "from labMTsimple.labMTsimple.storyLab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from database.bookclass import Book_raw_data\n",
    "\n",
    "import os\n",
    "sys.path.append('/Users/andyreagan/projects/2014/09-books/database')\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE','gutenbergdb.settings')\n",
    "import django\n",
    "django.setup()\n",
    "\n",
    "from library.models import *\n",
    "\n",
    "import pickle\n",
    "from rdflib import Graph\n",
    "import rdflib\n",
    "\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"data/gutenberg/rdf-data-all.pickle\",\"rb\")\n",
    "all_gut_metadata = pickle.loads(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51163"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_gut_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### that's less than 51249!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here are three specific things that I want\n",
    "gut_author_name = rdflib.term.URIRef('http://www.gutenberg.org/2009/pgterms/name')\n",
    "gut_lang = rdflib.term.URIRef('http://purl.org/dc/terms/language')\n",
    "gut_title = rdflib.term.URIRef('http://purl.org/dc/terms/title')\n",
    "gut_downloads = rdflib.term.URIRef('http://www.gutenberg.org/2009/pgterms/downloads')\n",
    "\n",
    "stuff_i_want = (gut_author_name,gut_lang,gut_title,gut_downloads)\n",
    "called = (\"authors\",\"lang_refs\",\"title\",\"downloads\")\n",
    "\n",
    "def read_rdf_2(g):\n",
    "    parse_result = {\"authors\": [],\n",
    "                    \"lang_refs\": [],\n",
    "                    \"title\": [],\n",
    "                    \"downloads\": [],}\n",
    "    for stmt in g:\n",
    "        if stmt[1] in stuff_i_want:\n",
    "            ind = called[stuff_i_want.index(stmt[1])]\n",
    "            parse_result[ind].append(stmt)\n",
    "    # go find the bibref that I need\n",
    "    parse_result[\"langs\"] = [\"\" for i in range(len(parse_result[\"lang_refs\"]))]\n",
    "    for i,lang_ref in enumerate(parse_result[\"lang_refs\"]):\n",
    "        for stmt in g:\n",
    "            if stmt[0] == lang_ref[2]:\n",
    "                parse_result[\"langs\"][i] = stmt\n",
    "    return parse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if isfile(\"data/gutenberg/all-book-metadata-51249.p\"):\n",
    "    all_book_metadata = pickle.load(open(\"data/gutenberg/all-book-metadata-51249.p\",\"rb\"))\n",
    "    all_book_metadata_raw = pickle.load(open(\"data/gutenberg/all-book-metadata-raw-51249.p\",\"rb\"))\n",
    "else:\n",
    "    # end_book = 20\n",
    "    end_book = 51249\n",
    "    all_book_metadata = [{} for i in range(end_book)]\n",
    "    all_book_metadata_raw = [{} for i in range(end_book)]\n",
    "    for i in range(end_book):\n",
    "        i=i+1\n",
    "        folder = join(\"data/gutenberg/cache/epub/\",str(i))\n",
    "        file = join(folder,\"pg{0}.rdf\".format(i))\n",
    "        if i%500 == 0:\n",
    "            print(file)\n",
    "        g = Graph()\n",
    "        g.parse(file, format=\"xml\")\n",
    "        p = read_rdf_2(g)\n",
    "        all_book_metadata_raw[i-1] = p\n",
    "        # stringify all of the entries\n",
    "        p_str = {}\n",
    "        for key in p:\n",
    "            p_str[key] = list(map(lambda x: str(x[2]),p[key]))\n",
    "        # print(p_str)\n",
    "        all_book_metadata[i-1] = p_str\n",
    "    pickle.dump(all_book_metadata,open(\"data/gutenberg/all-book-metadata-51249.p\",\"wb\"),pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(all_book_metadata_raw,open(\"data/gutenberg/all-book-metadata-raw-51249.p\",\"wb\"),pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(all_book_metadata):\n",
    "    fname = \"data/gutenberg/gutenberg-007/{0}.txt\".format(i+1)\n",
    "    \n",
    "    if len(Book.objects.filter(gutenberg_id=(i+1))) > 0:\n",
    "        continue\n",
    "    \n",
    "    if isfile(fname) and not isfile(\"data/gutenberg/gutenberg-008/{0}.p\".format(i+1)):\n",
    "        my_book_raw_data = Book_raw_data(filename=fname)\n",
    "        my_word_hash = {}\n",
    "        for word in my_book_raw_data.all_word_list:\n",
    "            if word not in my_word_hash:\n",
    "                my_word_hash[word] = 1\n",
    "        pickle.dump(my_book_raw_data,open(\"data/gutenberg/gutenberg-008/{0}.p\".format(i+1),\"wb\"))\n",
    "    elif isfile(\"data/gutenberg/gutenberg-008/{0}.p\".format(i+1)):\n",
    "        my_book_raw_data = pickle.load(open(\"data/gutenberg/gutenberg-008/{0}.p\".format(i+1),\"rb\"))\n",
    "        my_word_hash = {}\n",
    "        for word in my_book_raw_data.all_word_list:\n",
    "            if word not in my_word_hash:\n",
    "                my_word_hash[word] = 1\n",
    "        \n",
    "    my_authors = m[\"authors\"]\n",
    "    my_author_objects = []\n",
    "    for j,author in enumerate(my_authors):\n",
    "        # int(str(all_book_metadata_raw[0][\"authors\"][0][0]).split(\"/\")[-1])\n",
    "        if len(Author.objects.filter(fullname=author)) > 0:\n",
    "            my_author_objects.append(Author.objects.filter(fullname=author)[0])\n",
    "        else:\n",
    "            author_id = int(str(all_book_metadata_raw[i][\"authors\"][j][0]).split(\"/\")[-1])\n",
    "            a = Author(fullname=author,gutenberg_id=author_id)\n",
    "            a.save()\n",
    "            my_author_objects.append(a)\n",
    "    # many fields are optional....\n",
    "    if len(m[\"title\"]) > 0:\n",
    "        my_title = m[\"title\"][0]\n",
    "    else:\n",
    "        my_title = \"\"\n",
    "    if len(m[\"downloads\"]) > 0:\n",
    "        my_downloads = int(m[\"downloads\"][0])\n",
    "    else:\n",
    "        my_downloads = 0\n",
    "    if len(m[\"langs\"]) > 0:\n",
    "        my_lang = m[\"langs\"][0]\n",
    "        my_lang_id = lang_lookup(my_lang)\n",
    "    else:\n",
    "        my_lang = \"na\" # short for NOT AVAILABLE\n",
    "        my_lang_id = -1\n",
    "    # if this title already in there...skip\n",
    "    if len(Book.objects.filter(gutenberg_id=(i+1))) > 0:\n",
    "        continue\n",
    "    if isfile(fname):\n",
    "        full_text = open(fname,\"r\").read()\n",
    "        my_hash = hashlib.md5(full_text.encode(\"utf8\")).hexdigest()\n",
    "        my_book = Book(title=my_title,\n",
    "                       pickle_object=\"data/gutenberg/gutenberg-008/{0}.p\".format(i+1),\n",
    "                       hash=my_hash,\n",
    "                       # authors=my_author_objects,\n",
    "                       language=my_lang,\n",
    "                       lang_code_id=my_lang_id,\n",
    "                       downloads=my_downloads,\n",
    "                       from_gutenberg=True,\n",
    "                       gutenberg_id=(i+1),\n",
    "                       txt_file_path=fname,\n",
    "                       length=len(my_book_raw_data.all_word_list),\n",
    "                       numUniqWords=len(my_word_hash),\n",
    "                       exclude=False\n",
    "                    )\n",
    "        my_book.save()\n",
    "    else:\n",
    "        my_hash = \"\"\n",
    "        my_book = Book(title=my_title,\n",
    "                       hash=my_hash,\n",
    "                       # authors=my_author_objects,\n",
    "                       language=my_lang,\n",
    "                       lang_code_id=my_lang_id,\n",
    "                       downloads=my_downloads,\n",
    "                       from_gutenberg=True,\n",
    "                       gutenberg_id=(i+1),\n",
    "                       exclude=True,\n",
    "                       excludeReason=\"No file.\"\n",
    "                    )\n",
    "        my_book.save()\n",
    "    for a in my_author_objects:\n",
    "        my_book.authors.add(a)\n",
    "        my_book.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_book_metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(str(all_book_metadata_raw[0][\"authors\"][0][0]).split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_author_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
