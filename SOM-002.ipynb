{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (bookclass.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/andyreagan/projects/2014/09-books/notebooks/bookclass.py\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    if (\"START OF THIS PROJECT GUTENBERG EBOOK\" in line)\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, isdir\n",
    "from json import loads\n",
    "from re import findall,UNICODE\n",
    "import sys\n",
    "sys.path.append(\"/Users/andyreagan/tools/python\")\n",
    "from kitchentable.dogtoys import *\n",
    "from labMTsimple.labMTsimple.speedy import LabMT\n",
    "my_LabMT = LabMT()\n",
    "from labMTsimple.labMTsimple.storyLab import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "sys.path.append('/Users/andyreagan/projects/2014/09-books/database')\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE','gutenbergdb.settings')\n",
    "import django\n",
    "django.setup()\n",
    "\n",
    "from library.models import *\n",
    "from bookclass import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all our essentials\n",
    "from matplotlib import rc,rcParams\n",
    "# rc('font', family='sans-serif') \n",
    "# rc('font', serif='Helvetica Neue')\n",
    "# rc('text', usetex='false') \n",
    "\n",
    "rc('font', family='serif')\n",
    "rc('font', family='cmr10')\n",
    "rc('text', usetex='false') \n",
    "\n",
    "rcParams.update({'font.size': 12})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters = {\"min_dl\":40,\n",
    "           \"length\": [20000,100000],\n",
    "           \"P\": True,\n",
    "           \"n_points\": 200,\n",
    "           \"salad\": False,\n",
    "          }\n",
    "q = get_books(Book,filters)\n",
    "version_str = get_version_str(filters)\n",
    "this_dir = join(\"/Users/andyreagan/projects/2014/09-books/media/figures/SOM\",version_str)\n",
    "if not isdir(this_dir):\n",
    "    mkdir(this_dir)\n",
    "big_matrix = get_data(q,version_str,filters,use_cache=True)\n",
    "big_matrix_mean0 = big_matrix-np.tile(big_matrix.mean(axis=1),(200,1)).transpose()\n",
    "big_matrix_start0 = big_matrix-np.tile(big_matrix[:,0],(200,1)).transpose()\n",
    "print(big_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potentially useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mysub2ind(i,n,m):\n",
    "    # convert the i-th index of a flattened n x m matrix\n",
    "    # into the i,j of that matrix\n",
    "    j = int(np.floor(i/float(m)))\n",
    "    k = i-m*j\n",
    "    return j,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myind2sub(j,k,n,m):\n",
    "    # convert the [j,k]-th index of an n x m matrix\n",
    "    # into the i of the flattened matrix\n",
    "    i = j*n + k\n",
    "    return int(i)\n",
    "\n",
    "assert myind2sub(mysub2ind(20,15,15)[0],mysub2ind(20,15,15)[1],15,15) == 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the main function\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function [B,rmse_all] = train_SOM(A,B,C,numiter,randorder,scaling_fun,nbd_fun,iterstart)\n",
    "def train_SOM(data,node_states,network_size,numiter,scaling_fun,nbd_fun,randorder=True,iterstart=0,returnDis=False):\n",
    "    # train an SOM on the data, which is (sample x feature)\n",
    "    # i.e. books going down, timeseries going across (or PCA\n",
    "    # coeff across...)\n",
    "    # INPUTS\n",
    "    # data: (training pattern i, timeseries j)\n",
    "    # node_states: initial state of the nodes (num_nodes, features e.g. timeseries length)\n",
    "    # network_size: tuple of (m,n) size of the network\n",
    "\n",
    "    num_training_patterns = data.shape[0]\n",
    "    print(num_training_patterns)\n",
    "    num_nodes = node_states.shape[0]\n",
    "    # or, network_size[0]*network_size[1]\n",
    "    # precompute the distance from each node, to the others\n",
    "    # this is a distance matrix\n",
    "    # I'm thinking about this as taking steps on the grid\n",
    "    # and no torus\n",
    "    pairwise_distances = np.zeros([num_nodes,num_nodes])\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            ind1 = mysub2ind(i,network_size[0],network_size[1])\n",
    "            ind2 = mysub2ind(j,network_size[0],network_size[1])\n",
    "            pairwise_distances[i,j] = np.abs(ind1[0]-ind2[0])+np.abs(ind1[1]-ind2[1])\n",
    "    print(\"pairwise distance:\")\n",
    "    print(pairwise_distances[5,:])\n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.imshow(pairwise_distances)\n",
    "    # plt.title('pairwise distance matrix')\n",
    "    # mysavefig('SOM-5x5-distanceMatrix.png')\n",
    "    # plt.show()\n",
    "\n",
    "    rmse_avg = np.zeros(numiter)\n",
    "\n",
    "    print('going for {0} iterations now'.format(numiter))\n",
    "    for i in tqdm(range(iterstart,numiter+iterstart)):\n",
    "        # print('on training iteration no {0}'.format(i))\n",
    "        order = np.arange(num_training_patterns)\n",
    "        # order = np.arange(1)\n",
    "\n",
    "        if randorder:\n",
    "            np.random.shuffle(order)\n",
    "\n",
    "        # go get the scaling parameter\n",
    "        scaling_coeff = scaling_fun(i)\n",
    "        # print('scaling coeff is {0}'.format(scaling_coeff))\n",
    "        \n",
    "        # print(order)\n",
    "        for j in order:\n",
    "            # find the index of the winner\n",
    "            # print(data[j,:])\n",
    "            diff = node_states-data[j,:]\n",
    "            dist = np.sqrt(np.sum(diff**2,axis=(1)))\n",
    "            # print(dist)\n",
    "            min_dist = dist.min()\n",
    "            winning_node = dist.argmin()\n",
    "\n",
    "            # print('winning node is {0}'.format(winning_node))\n",
    "            rmse_avg[i-iterstart] += min_dist\n",
    "            nbd,nbd_coeffs = nbd_fun(i,pairwise_distances[winning_node,:])\n",
    "            # print('tuning the nbd of size {0}'.format(len(nbd)))\n",
    "            # print(nbd)\n",
    "            for n,a in zip(nbd,nbd_coeffs):\n",
    "                # print(n)\n",
    "                # print(a.shape)\n",
    "                # print(node_states[n,:])\n",
    "                # print(data[j,:].shape)\n",
    "                # print(node_states[n,:]-data[j,:])\n",
    "                # print(scaling_coeff)\n",
    "                # print(a)\n",
    "                node_states[n,:] = node_states[n,:] - scaling_coeff*a*(node_states[n,:]-data[j,:])\n",
    "                # print('after:')\n",
    "                # print(node_states[n,:])\n",
    "\n",
    "    # here is the MATLAB code for this:\n",
    "    # % INPUTS\n",
    "    # %\n",
    "    # % A(size input,num training patterns)\n",
    "    # % the training patterns\n",
    "    # %\n",
    "    # % B(size input,num nodes in kohonen)\n",
    "    # % the m_i states of the nodes\n",
    "    # %\n",
    "    # % C(num nodes,num nodes)\n",
    "    # % adjacency matrix for the nodes\n",
    "    # %\n",
    "    # % OUTPUT\n",
    "    # %\n",
    "    # % B: kohenen matrix values\n",
    "    # \n",
    "    # % how long to train\n",
    "    # % numiter = 50;\n",
    "    # % taking this from input\n",
    "    # \n",
    "    # num_training_patterns = length(A(1,:));\n",
    "    # num_nodes = length(B(1,:));\n",
    "    # \n",
    "    # % rmse_all = ones(num_training_patterns+(1-traintogether)* ...\n",
    "    # %                 num_training_patterns,numiter);\n",
    "    # rmse_all = ones(num_training_patterns,numiter);\n",
    "    # \n",
    "    # fprintf('training\\n');\n",
    "    # for i=1+iterstart:numiter+iterstart\n",
    "    #     fprintf('on training iteration no %f\\n',i);\n",
    "    #     if randorder\n",
    "    #         order = 1:num_training_patterns;\n",
    "    #     else\n",
    "    #         order = randperm(num_training_patterns);\n",
    "    #     end\n",
    "    #     scaling_coeff = scaling_fun(i);\n",
    "    #     fprintf('scaling coeff is %f\\n',scaling_coeff);\n",
    "    #     for j=order\n",
    "    #         % find the index of the winner\n",
    "    #         min_dist = sqrt(sum((A(:,j)-B(:,1)).^2));\n",
    "    #         winning_node = 1;\n",
    "    #         for k=2:num_nodes\n",
    "    #             dist = sqrt(sum((A(:,j)-B(:,k)).^2));\n",
    "    #             if dist<min_dist\n",
    "    #                 min_dist = dist;\n",
    "    #                 winning_node = k;\n",
    "    #             end\n",
    "    #         end\n",
    "    #         % fprintf('winning node is %f\\n',winning_node);\n",
    "    #         rmse_all(j,i-iterstart) = min_dist;\n",
    "    #         [nbd,nbd_coeffs] = nbd_fun(i,winning_node,C);\n",
    "    #         % fprintf('tuning the nbd of size %f\\n',length(nbd))\n",
    "    #         for k=1:length(nbd)\n",
    "    #             B(:,nbd(k)) = B(:,nbd(k)) - scaling_coeff*nbd_coeffs(k)*(B(:,nbd(k))-A(:,j));\n",
    "    #         end\n",
    "    #     end\n",
    "    #     % rmse_avg(1,i) = mean(rmse_all(:,i));\n",
    "    # end\n",
    "    # I'm not going to need an adjacency matrix...I'm just going to go for a simpler grid model\n",
    "    \n",
    "    if returnDis:\n",
    "        return node_states,rmse_avg,pairwise_distances\n",
    "    else:\n",
    "        return node_states,rmse_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some quick functions for the scalings\n",
    "def scaling_fun_alpha(i,alpha):\n",
    "    return np.power(i+1,alpha)\n",
    "\n",
    "def nbd_fun_alpha(iteration,distance_list,alpha):\n",
    "    tmp = np.arange(distance_list.shape[0])\n",
    "    tmp2 = np.ones(distance_list.shape[0])\n",
    "    max_d = network_size[0]*np.power(iteration+1,alpha)\n",
    "    # max_d = 3.0\n",
    "    return tmp[distance_list < max_d],tmp2[distance_list < max_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RMSE(a,b):\n",
    "    return np.sqrt(np.sum(np.power((a-b),2)))\n",
    "\n",
    "def plot_B_matrix(trained_nodes,network_size,cmap=\"Greys\",d=RMSE,shrink=.7):\n",
    "    # plot the B-matrix\n",
    "    B = np.zeros(np.array(network_size)*2-1)\n",
    "    # march across and fill out this bad boy\n",
    "    # entries at the nodes are the mean distance to all neighbors\n",
    "    # entries inbetween are, inbetween (or the mean of two inbetweens)\n",
    "\n",
    "    # go down on the ones with nodes\n",
    "    # these are the betweens horizontally\n",
    "    \n",
    "    # going to replace RMSE with my own distance metric\n",
    "    for j in np.arange(0,B.shape[0],dtype=int): # down\n",
    "        for i in np.arange(0,B.shape[1],dtype=int): # across\n",
    "            if not np.mod(j,2) and not np.mod(i,2): # if both even\n",
    "                B[j,i] = 0\n",
    "            if np.mod(j,2) and not np.mod(i,2): # if down odd, across even\n",
    "                up = trained_nodes[myind2sub((j-1)/2,i/2,network_size[0],network_size[1]),:]\n",
    "                down = trained_nodes[myind2sub((j+1)/2,i/2,network_size[0],network_size[1]),:]\n",
    "                B[j,i] = d(up,down)\n",
    "            if not np.mod(j,2) and np.mod(i,2): # if down even, across odd\n",
    "                left = trained_nodes[myind2sub(j/2,(i-1)/2,network_size[0],network_size[1]),:]\n",
    "                right = trained_nodes[myind2sub(j/2,(i+1)/2,network_size[0],network_size[1]),:]\n",
    "                B[j,i] = d(left,right)\n",
    "            if np.mod(j,2) and np.mod(i,2): # if down odd, across odd\n",
    "                upleft = trained_nodes[myind2sub((j-1)/2,(i-1)/2,network_size[0],network_size[1]),:]\n",
    "                downleft = trained_nodes[myind2sub((j+1)/2,(i-1)/2,network_size[0],network_size[1]),:]\n",
    "                upright = trained_nodes[myind2sub((j-1)/2,(i+1)/2,network_size[0],network_size[1]),:]\n",
    "                downright = trained_nodes[myind2sub((j+1)/2,(i+1)/2,network_size[0],network_size[1]),:]\n",
    "                B[j,i] = (d(up,down)+d(left,right))/2\n",
    "    # print(B)\n",
    "    plt.imshow(B, aspect=1, cmap=plt.get_cmap(cmap), origin='lower', interpolation='nearest', extent=(-0.25,network_size[0]-0.75,-0.25,network_size[1]-0.75))\n",
    "    plt.colorbar(shrink=shrink)\n",
    "    # mysavefig('SOM-Animals-{0}x{0}-U-Matrix.png'.format(network_size[0]))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do this for the book data\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start with 20x20\n",
    "# network_size = (13,13)\n",
    "network_size=(8,8)\n",
    "# network_size = (5,5)\n",
    "num_nodes = network_size[0]*network_size[1]\n",
    "node_states = np.random.randn(num_nodes,big_matrix.shape[1])*.05\n",
    "\n",
    "# define some quick functions for the scalings\n",
    "def scaling_fun_alpha(i,alpha):\n",
    "    return np.power(i+1,alpha)\n",
    "\n",
    "def nbd_fun_alpha(iteration,distance_list,alpha):\n",
    "    tmp = np.arange(distance_list.shape[0])\n",
    "    tmp2 = np.ones(distance_list.shape[0])\n",
    "    max_d = np.sqrt(num_nodes)*np.power(iteration+1,alpha)\n",
    "    # max_d = 3.0\n",
    "    return tmp[distance_list < max_d],tmp2[distance_list < max_d]\n",
    "\n",
    "iterations = 500\n",
    "trained_nodes,rmse = train_SOM(big_matrix_mean0,\n",
    "                               node_states,\n",
    "                               network_size,\n",
    "                               iterations,\n",
    "                               lambda x: scaling_fun_alpha(x,-0.15),\n",
    "                               lambda x,y: nbd_fun_alpha(x,y,-0.10))\n",
    "    \n",
    "# print(trained_nodes)\n",
    "# print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(range(iterations),rmse,\".1\",linewidth=1.5)\n",
    "# plt.title('SOM RMSE')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "mysavefig('SOM-{0}x{0}-RMSE.pdf'.format(network_size[0]),folder=this_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = big_matrix\n",
    "winning_node_list = np.zeros(data.shape[0])\n",
    "for j in range(data.shape[0]):\n",
    "    diff = trained_nodes-data[j,:]\n",
    "    dist = np.sqrt(np.sum(diff**2,axis=(1)))\n",
    "    winning_node_list[j] = dist.argmin()\n",
    "plt.figure(figsize=(4,4))\n",
    "n,bins,patches = plt.hist(winning_node_list,bins=num_nodes)\n",
    "# plt.title('SOM Winning Nodes')\n",
    "plt.xlabel(\"SOM Node\")\n",
    "plt.ylabel(\"Number winning arcs\")\n",
    "mysavefig('SOM-{0}x{0}-node-hist.pdf'.format(network_size[0]),folder=this_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now let's also plot them\n",
    "def plot_clusters(clusters,data,cluster_centers,cluster_id,v=True,fix_ylim=True,xspacing=.01,investigate=False,save=True):\n",
    "    # we are going to make plots of max width 3\n",
    "    num_x = np.min([3,len(clusters)])\n",
    "    num_y = np.ceil(len(clusters)/num_x)\n",
    "    xspacing = .03\n",
    "    yspacing = .03\n",
    "    xoffset = .07\n",
    "    yoffset = .07\n",
    "    xwidth = (1.-xoffset)/(num_x)-xspacing\n",
    "    yheight = (1.-yoffset)/(num_y)-yspacing\n",
    "    print('xwidth is {0}'.format(xwidth))\n",
    "    print('yheight is {0}'.format(yheight))\n",
    "    \n",
    "    # go compute the ybounds:\n",
    "    calc_ylim = [100.0,-100.0]\n",
    "    for cluster in clusters:\n",
    "        c_max = data[cluster[0][:20],:].max()\n",
    "        c_min = data[cluster[0][:20],:].min()\n",
    "        calc_ylim[0] = np.min([calc_ylim[0],c_min])\n",
    "        calc_ylim[1] = np.max([calc_ylim[1],c_max])\n",
    "        \n",
    "    chars = 60\n",
    "    \n",
    "    scale_factor_x = 5\n",
    "    scale_factor_y = 5*1.25\n",
    "    if investigate:\n",
    "        scale_factor_x = 10\n",
    "        scale_factor_y = 10*1.25\n",
    "    fig = plt.figure(figsize=(scale_factor_x*num_x,scale_factor_y*num_y))\n",
    "    for i,cluster in enumerate(clusters):\n",
    "        print(i)\n",
    "        print(\"====\")\n",
    "        # print((i-i%num_x))\n",
    "        # ind = np.argsort(w[:,sv+svstart])[-20:]\n",
    "        ax1rect = [xoffset+(i%num_x)*(xspacing+xwidth),1.-yheight-yspacing-(int(np.floor((i-i%num_x)/num_x))*(yspacing+yheight))+yheight*.2,xwidth,yheight*.8]\n",
    "        ax1 = fig.add_axes(ax1rect)\n",
    "        ax1books_rect = ax1rect.copy()\n",
    "        ax1books_rect[1] -= yheight*.2\n",
    "        ax1books_rect[3] = yheight*.2\n",
    "        ax1books = fig.add_axes(ax1books_rect)\n",
    "        # ax1books.text?\n",
    "        # ax.set_title('20 closest positive correlates')\n",
    "        \n",
    "        if v:\n",
    "            print('-'*80)\n",
    "            print('20 closest positive correlates:')\n",
    "            # print(cluster)\n",
    "        j=0\n",
    "        for index,title in zip(*cluster):\n",
    "            if j+1 > 20:\n",
    "                break\n",
    "            if investigate:\n",
    "                ax1.plot(data[index],label=\"{} ({})\".format(title,q[int(index)].gutenberg_id))\n",
    "            else:\n",
    "                ax1.plot(data[index],color=\".4\",label=None)\n",
    "            # plt.plot(big_matrix_mean0[i],color=\".4\")\n",
    "            if v:\n",
    "                print(index,title)\n",
    "            if j<5:\n",
    "                ax1books.text(0.0,.8-j*.2,\"{} ({})\".format(title,q[int(index)].gutenberg_id),fontsize=10)\n",
    "            j+=1\n",
    "        ax1.plot(cluster_centers[cluster_id[i]],color=\"#ff6700\",linewidth=2,label=\"Node {} Cluster {} ({})\".format(cluster_id[i],i+1,len(cluster[0])))\n",
    "        # ax1.set_xticklabels([])\n",
    "        ax1.legend(loc=\"upper right\")\n",
    "\n",
    "        # ax1.axis('off')\n",
    "        ax1books.axis('off')\n",
    "        \n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=1.0)\n",
    "        # fig.text(ax1rect[0]+.03/xwidth, ax1rect[1]+ax1rect[3]-.03/yheight, letters[i],\n",
    "        if fix_ylim:\n",
    "            my_ylim = calc_ylim\n",
    "        else:\n",
    "            my_ylim = ax1.get_ylim()\n",
    "        ax1.text(.035*200, my_ylim[0]+.965*(my_ylim[1]-my_ylim[0]), letters[i],\n",
    "                     fontsize=14,\n",
    "                     verticalalignment='top',\n",
    "                     horizontalalignment='left',\n",
    "                     bbox=props)\n",
    "\n",
    "        if fix_ylim:\n",
    "            ax1.set_ylim(calc_ylim)\n",
    "        if fix_ylim and i%num_x > 0:\n",
    "            ax1.set_yticklabels([])\n",
    "        if True: # i<num_x*(num_y-1): # only on the bottom row\n",
    "            ax1.set_xticklabels([])\n",
    "            \n",
    "    if save:\n",
    "        # mysavefig('SV{0}.svg'.format('4-6'))\n",
    "        mysavefig(\"clustered-timeseries.pdf\".format(),\n",
    "                  folder=this_dir,\n",
    "                  openfig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDistances = pickle.load(open(\"/Users/andyreagan/projects/2014/09-books/data/gutenberg/pairwise-distance-matrix-cache.p\",\"rb\"))\n",
    "allDistancesCentered = pickle.load(open(\"/Users/andyreagan/projects/2014/09-books/data/gutenberg/pairwise-distance-mean0-matrix-cache.p\",\"rb\"))\n",
    "allDistancesStart = pickle.load(open(\"/Users/andyreagan/projects/2014/09-books/data/gutenberg/pairwise-distance-start0-matrix-cache.p\",\"rb\"))\n",
    "\n",
    "def cityBlock(a,b):\n",
    "    return np.sum(np.abs(a-b))\n",
    "\n",
    "def get_sorted(all_ind,center=[]):\n",
    "    if len(center) ==  0:\n",
    "        # go get the submatrix\n",
    "        # allDistances[[1,2,3],:][:,[1,2,3]]\n",
    "        submat = allDistances[all_ind,:][:,all_ind]\n",
    "        # print(submat)\n",
    "        distances = submat.sum(axis=0)\n",
    "    else:\n",
    "        # ---------\n",
    "        # that did distance from the other stories...\n",
    "        # let's look at distance from the SOM story?\n",
    "        distances = [cityBlock(center,big_matrix_mean0[all_ind[i],:]) for i in all_ind]\n",
    "    \n",
    "    # print(distances)\n",
    "    indices_sorted = sorted(range(len(all_ind)),key=lambda i: distances[i])\n",
    "    all_ind_sorted = all_ind[indices_sorted]\n",
    "    distances_sorted = distances[indices_sorted]\n",
    "    # print(all_ind_sorted)\n",
    "    # make sure they're sorted the right way!\n",
    "    # print(distances_sorted)\n",
    "    assert distances_sorted[0] < distances_sorted[1]\n",
    "    titles_sorted = [\"\" for i in range(len(all_ind_sorted))]\n",
    "    chars = 50\n",
    "    for i,ind in enumerate(all_ind_sorted):\n",
    "        b = q[int(ind)]\n",
    "        if len(b.title) > chars:\n",
    "            titles_sorted[i] = \"{}. {}...\".format(i+1,b.title[:chars-3].replace(\"\\n\",\": \").replace(\"&\",\"\\&\"))\n",
    "        else:\n",
    "            titles_sorted[i] = \"{}. {}\".format(i+1,b.title.replace(\"\\n\",\": \").replace(\"&\",\"\\&\"))\n",
    "    return all_ind_sorted,titles_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's look at what we have to build the data to plot. here are the trained nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winning_node_list.shape\n",
    "# looks like a list of the winning node for each story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winning_node_list[:10]\n",
    "# peek at the winning nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n\n",
    "# this is binned onto each node index by plt.hist() (count of wins by node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(n)\n",
    "# make sure I have 100 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# must have done a 10x10!\n",
    "# let's rebuild n anyway\n",
    "n_nodes = [np.nonzero(winning_node_list==i)[0] for i in range(num_nodes)]\n",
    "print(n_nodes)\n",
    "n = list(map(len,n_nodes))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_indexer = sorted(range(len(n)),key=lambda i: n[i],reverse=True)\n",
    "# let's sort the winning nodes\n",
    "print(n_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sorted = [n[n_i] for n_i in n_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sorted[:9]\n",
    "# okay, now we have sorted counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_indexer[:9]\n",
    "# and the sorted nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winning_node_list==n_indexer[0]\n",
    "# these are the stories that match winning node 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nonzero(winning_node_list==82)\n",
    "# here are their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.nonzero(winning_node_list==82)[0])\n",
    "# and BOOM there are 59 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = [get_sorted(n_nodes[n_i]) for n_i in n_indexer[:9]]\n",
    "# clusters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_clusters(clusters,big_matrix_mean0,trained_nodes,n_indexer,v=False,fix_ylim=True,xspacing=.01,investigate=False,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cityBlock(trained_nodes[n_indexer[1],:],trained_nodes[n_indexer[2],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "plot_B_matrix(trained_nodes,network_size,cmap=\"Greys\",d=cityBlock,shrink=.8)\n",
    "for i in range(9):\n",
    "    if i==0:\n",
    "        color=\".1\"\n",
    "    else:\n",
    "        color=\".1\"\n",
    "    plt.text(mysub2ind(n_indexer[i],network_size[0],network_size[0])[1],\n",
    "             mysub2ind(n_indexer[i],network_size[0],network_size[0])[0],\n",
    "             letters[i],\n",
    "             ha=\"center\",\n",
    "             va=\"center\",\n",
    "             fontsize=10,\n",
    "             color=color)\n",
    "plt.xlabel(\"$N_i$\")\n",
    "plt.ylabel(\"$N_j$\")\n",
    "\n",
    "mysavefig(\"Bmatrix-labeled.pdf\",folder=this_dir,openfig=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "plt.imshow(np.reshape(n,network_size), aspect=1, cmap=plt.get_cmap('Greys'), origin='lower', interpolation='nearest', ) #extent=(-0.25,network_size[0]-0.75,-0.25,network_size[1]-0.75))\n",
    "plt.colorbar(shrink=.8)\n",
    "plt.xlim()\n",
    "for i in range(9):\n",
    "    if i==0:\n",
    "        color=\".99\"\n",
    "    else:\n",
    "        color=\".99\"\n",
    "    plt.text(mysub2ind(n_indexer[i],network_size[0],network_size[0])[1],\n",
    "             mysub2ind(n_indexer[i],network_size[0],network_size[0])[0],\n",
    "             letters[i],\n",
    "             ha=\"center\",\n",
    "             va=\"center\",\n",
    "             fontsize=10,\n",
    "             color=color)\n",
    "    \n",
    "plt.xlabel(\"$N_i$\")\n",
    "plt.ylabel(\"$N_j$\")\n",
    "\n",
    "\n",
    "mysavefig(\"heatmap-labeled.pdf\",folder=this_dir,openfig=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cmd = \"/Users/andyreagan/tools/shell/2015-08-kitchentabletools/pdftile.pl 1 2 0.48 3 0 l 8 \\\"\\\" \\\"\\\" {0}/Bmatrix-labeled.pdf \\\"\\\" {0}/heatmap-labeled.pdf {0}/SOM-matrices\".format(this_dir)\n",
    "# ~/tools/shell/2015-08-kitchentabletools/pdftile.pl 1 3 0.3 3 0 l 8 \"\" \"\" 2016-03-11-15-10-training.pdf \"\" 2016-03-11-15-13-Bmatrix-labeled.pdf \"\" 2016-03-11-15-14-heatmap-labeled.pdf SOM\n",
    "subprocess.call(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
